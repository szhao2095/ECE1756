\documentclass[12pt,letterpaper]{article}
\usepackage{fullpage}
\usepackage[top=2cm, bottom=4.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{lastpage}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage[table,xcdraw]{xcolor}
\usepackage{siunitx}
\usepackage{minted}

\hypersetup{%
  colorlinks=true,
  linkcolor=blue,
  linkbordercolor={0 0 1}
}

\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}

% Edit these as appropriate
\newcommand\course{ECE 1756}
\newcommand\hwnumber{3}
\newcommand\NetIDa{1003273913}

\pagestyle{fancyplain}
\headheight 35pt
\lhead{\NetIDa}
\chead{\textbf{\Large Assignment \hwnumber}}
\rhead{\course \\ \today}
\lfoot{}
\cfoot{}
\rfoot{\small\thepage}
\headsep 1.5em

\begin{document}

\section*{1.0 Introduction}

The following document serves as the lab report for assignment 3 of ECE 1756 (Fall 2021). This report is written by Sheng Zhao (1003273913).

Section 2.0 describes the C++ implementation of the desired logical RAM mapping application as well as the the means by which it is further optimized. Section 3.0 then presents and evaluates the mappings produced by this implementation. Finally, a brief Section 4.0 covers the potential future work that can be done to improve upon the current implementation.

\clearpage
\section*{2.0 RAM Mapper}

The objective of the assignment is to create a RAM mapping tool that produces a legal mapping of desired logical RAMs to available physical RAMs. A total of roughly 15000 different logical RAMs across 69 circuits serves as the benchmark of the implementation, with the area metric calculated by the checker executable provided by the course serving as the evaluation criteria. Details of the problem statement can be found within the lab manual.

The RAM mapping functionality is implemented using C++ in an Object Oriented Programming fashion. This section details the process that led to the final implementation. Skip to subsection 2.4 for the final implementation. Big O notation will only be given for the final implementation's core calculations (initialization portions are skipped). Note that due to time constraints, the implementation only ever map logical RAMs to a single type of physical RAM.

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{single_ram_pram_usage.png}
\caption{Physical RAM usage for single ram type mapping}
\label{fig:single_ram_pram_usage}
\end{figure}
\clearpage

To help illustrate how well the instantiated physical RAMs are being utilized, Fig. \ref{fig:single_ram_pram_usage} (python code used to generate this can be found in Appendix A) was generated by first computing the percentage of total logical bits over the total physical bits within the RAM that it is mapped to. The 15000 total data points are then placed into ten buckets based on this percentage value. In essence, the intuition is that the larger the utilization the better (and less area is wasted) and this is represented with a higher count in the lower buckets (on the left). 

In general, it would seem like the final implementation (in red) has shown an improvement when compared to the initial implementation (in blue). There is a decrease in counts for buckets for 50\%~90\% and increase in counts for buckets of lower wastage percentages. However, the final bucket for 90\%~100\% showed an increase which suggest that some other optimization method other than sharing and improving the cost function (explained in the following subsections) might be required.

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{single_ram_tile_usage.png}
\caption{Tile usage for single ram type mapping}
\label{fig:single_ram_tile_usage}
\end{figure}

A similar computation is done for Fig. \ref{fig:single_ram_tile_usage} (python code in Appendix B) for how well the logic block count relates to the total final tile count. Having a large discrepancy between the two values for each circuit (graphically this means more data points falling in the lower buckets, i.e. lower usage) means that one physical RAM type might be overused, leading to more tiles being needed. As shown in the figure, the final implementation (in red) showed improvement over the initial (in blue) with more circuits utilizing more of the available tiles. 

\clearpage
\subsection*{2.1 Single Ram Type - Simple}

The RAM mapping tool began with just a simple idea, to map each logical RAM, regardless of which circuit they belong to. The main computation essentially produces a solution for each logical RAM requested for each type of physical RAM, and the lowest cost solution is then chosen to be the final solution. In the event that the physical RAM can operate in different widths, all combinations that do not violate any legality checks are considered. To keep computations simple, the cost function used is simply the area of the physical RAM used (i.e. logic block areas for LUTRAMs, BRAM areas for BRAMs, additional required LUTs are included). 

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{single_ram_circuit_area_checker_simple.png}
\caption{Area usage for simple implementation}
\label{fig:single_ram_circuit_area_checker_simple}
\end{figure}

\clearpage
\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{checker_simple_area.jpg}
\caption{Geometric average for simple implementation}
\label{fig:checker_simple_area}
\end{figure}

With the simple implementation, a mapping was computed and evaluated using the provided checker executable. A geometric average area of \num{2.63699e8} MWTAs (Fig. \ref{fig:checker_simple_area}) is obtained and Fig. \ref{fig:single_ram_circuit_area_checker_simple} (python script in Appendix C) shows the area usage for each of the 69 circuits.

In addition, with respect to Fig. \ref{fig:single_ram_pram_usage}, The simple implementation (shown in blue) seems to be under utilizing the physical RAMs that are instantiated as most of these physical RAMs are seeing more than 50\% of their available space wasted.

\clearpage
\subsection*{2.2 Single Ram Type - Shared}

With under utilization in mind, an effort was made to share the physical RAMs are much as possible. To facilitate the sharing of physical RAM, a map of logical RAM width to a vector of logical RAM IDs is created during initialization when the test cases are being read in. The vectors of logical RAMs are also sorted based on the logical RAM depth in descending order.

Building on top of the simple implementation, every time a solution is explored for the current logical RAM, a lookup is also performed into this newly created map. This is done first with the width that is currently being explored and, should no valid candidate be found, smaller widths in powers of two. Each candidate is checked for validity based on their required modes, the physical RAM's current operating mode, whether if their width is possible with the physical RAM in TrueDualPort mode, whether if they are already mapped, etc. The cost function for the current logical RAM is adjusted according to the ratio of the two logical RAM's total bit requirements. This translates to a strict decrease in cost in all cases. Should a solution with RAM sharing be chosen, this entry is recorded twice, once for each logical RAM, and both logical RAMs are marked as done.

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{single_ram_circuit_area_checker_shared.png}
\caption{Area usage for shared implementation}
\label{fig:single_ram_circuit_area_checker_shared}
\end{figure}

\clearpage
\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{checker_shared_area.jpg}
\caption{Geometric average for shared implementation}
\label{fig:checker_shared_area}
\end{figure}

With the shared implementation, a geometric average area of \num{2.64334e8} MWTAs (Fig. \ref{fig:checker_simple_area}) is obtained which is higher than before. The breakdown of area usage in Fig. \ref{fig:single_ram_circuit_area_checker_simple} shows that while circuit 59 has seen a halving in area requirement, many other circuits are in fact using more area than before. This is likely due to the inaccurate cost function which only accounts for the current logical RAM that is being evaluated.

It is also interesting to note that Fig. \ref{fig:single_ram_pram_usage} shows that sharing physical RAM does indeed increase utilization. However, the increase in geomtric average area suggests that the initial intuition of percentage of physical RAM utilized is closely related to area is untrue.

\clearpage
\subsection*{2.3 Single Ram Type - Modified Cost Function}

With the cost function in mind, an implementation was done on top of the simple implementation as a proof of concept with lower complexity in the code. The improved cost function does not only account for the area required by the physical RAMs themselves, but also any additional area incurred when the use of the desired physical RAM requires more logic blocks. For example, if based on the current number of logic blocks there are only X number of BRAM8192 blocks and the current solution (that is being evaluated) requires Y more than the limit, the cost function will also include the instantiation of an addition Y times the ratio (10 in this case for Stratix-IV) number of logic blocks. 

The modified cost function begins by computing the existing amount of each type of physical RAM based on the logic blocks used for the circuit logic. With each iteration, the number and type of physical RAM chosen for each solution is recorded. When a potential solution seeks to use a RAM type that is not available anymore, the addition cost is accounted for. This has the effect of delaying the use of unavailable physical RAM type. When a solution is chosen, and should it exceed the currently available amount, a new total of each RAM type is computed based on the new logic block count (e.g. using an extra BRAM128K causes 300 more logic blocks to be added, which is 30 more BRAM8192 blocks).

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{single_ram_circuit_area_checker_modifiedcostfunction.png}
\caption{Area usage for modified cost function implementation}
\label{fig:single_ram_circuit_area_checker_modifiedcostfunction}
\end{figure}

\clearpage
\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{checker_modifiedcostfunction_area.jpg}
\caption{Geometric average for modified cost function implementation}
\label{fig:checker_modifiedcostfunction_area}
\end{figure}

The modified cost function is a success and brought the geometric average area down to \num{2.22393e8} MWTAs (Fig. \ref{fig:checker_modifiedcostfunction_area}) and Fig. \ref{fig:single_ram_circuit_area_checker_modifiedcostfunction} also shows a significant decrease in area used for many circuits.

\clearpage
\subsection*{2.4 Single Ram Type - Modified Cost Function with Sharing}

Getting to the final implementation, the modified cost function and physical RAM sharing components are merged into a single function with both implementations still operating the same way they did before.

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{single_ram_circuit_area_checker_modifiedcostfunction_withsharing.png}
\caption{Area usage for modified cost function with physical RAM sharing implementation}
\label{fig:single_ram_circuit_area_checker_modifiedcostfunction_withsharing}
\end{figure}
\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{checker_modifiedcostfunction_withsharing_area.jpg}
\caption{Geometric average for modified cost function with physical RAM sharing implementation}
\label{fig:checker_modifiedcostfunction_withsharing_area}
\end{figure}

The addition of the physical RAM sharing portion further improved the geometric average area to \num{2.21838e8} MWTAs (Fig. \ref{fig:checker_modifiedcostfunction_withsharing_area}). Similar to when we switched from simple to shared implementations Fig. \ref{fig:single_ram_circuit_area_checker_modifiedcostfunction_withsharing} shows the same decrease for circuit 59 and slight increase in area usage for a few other circuits once again.

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{run_time.jpg}
\caption{Average time taken}
\label{fig:run_time}
\end{figure}

The final implementation took an average of 0.60 seconds to complete the entire computation (including initialization) over 20 runs (Fig. \ref{fig:run_time}). The command needed to run the mapping tool with Stratix-IV architecture is ./mapper 1.

\subsubsection*{2.4.1 Big O}


\clearpage
\section*{3.0 Results}

\subsection*{3.1 Stratix-IV Architecture}

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{table_1_top.jpg}
\caption{Checker output for Stratix-IV architecture (top)}
\label{fig:table_1_top}
\end{figure}
\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{table_1_bot.jpg}
\caption{Checker output for Stratix-IV architecture (bot)}
\label{fig:table_1_bot}
\end{figure}

\clearpage
\subsection*{3.2 Single Physical RAM Type w/ and w/o LUTRAMs}

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{single_ram_explore_summary_1.jpg}
\caption{Explore summary without configuring BRAM128K for checker}
\label{fig:single_ram_explore_summary_1}
\end{figure}
\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{single_ram_explore_summary_2.jpg}
\caption{Explore summary with configuring BRAM128K for checker}
\label{fig:single_ram_explore_summary_2}
\end{figure}

To facilitate the design exploration with a single type of physical RAM with and without LUTRAMs, a short python script (Appendix D) was written that works in conjunction with the mapping tool to execute the roughly 600 different combinations of max BRAM size, with different widths and ratios, as well as with and without LUTRAMs. For each max size from 1K to 128K, widths of 2 to 128 bits are tested. Each set of these different max widths are also tested with ratios of 10, 25, 50, 100 (for sizes up to 16K), 150 (for 32K), 200 (for 64K), 300 (for 128K). Finally, the whole test set is rerun with LUTRAMs enabled.

Fig. \ref{fig:single_ram_explore_summary_1} and Fig. \ref{fig:single_ram_explore_summary_2} shows the summary of the exploration and the full dump file can be found in Appendix E. Results shown in Fig. \ref{fig:single_ram_explore_summary_1} and Fig. \ref{fig:single_ram_explore_summary_2} are used to prepare columns 4 and 5 Table \ref{tab:explore_results_no_lutram} and Table \ref{tab:explore_results_lutram}. The reason for duplicate results are explained in subsection 3.2.1

\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{\begin{tabular}[c]{@{}c@{}}BRAM\\ Size\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Max \\ Width\end{tabular}} &
  \textbf{LBs / BRAM} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Geometric Average \\ FPGA Area \\ (MWTAs)\\ W/O BRAM128K\\ Configured\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Geometric Average \\ FPGA Area \\ (MWTAs) \\ W/ BRAM128K \\ Configured\end{tabular}} \\ \hline
1 kbit   & 32  & 10 & \num{5.93618e8} & \num{6.31963e8} \\ \hline
2 kbit   & 32  & 10 & \num{3.9355e8} & \num{4.18424e8} \\ \hline
4 kbit   & 32  & 10 & \num{2.9374e8} & \num{3.11729e8} \\ \hline
8 kbit   & 32  & 10 & \num{2.45914e8} & \num{2.59351e8} \\ \hline
16 kbit  & 64  & 10 & \num{2.34049e8} & \num{2.45565e8} \\ \hline
32 kbit  & 64  & 10 & \num{2.53983e8} & \num{2.648e8} \\ \hline
64 kbit  & 128 & 25 & \num{2.99826e8} & \num{3.13981e8} \\ \hline
128 kbit & 128 & 25 & \num{3.56863e8} & \num{3.70499e8} \\ \hline
\end{tabular}
\caption{Results without LUTRAM}
\label{tab:explore_results_no_lutram}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{\begin{tabular}[c]{@{}c@{}}BRAM\\ Size\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Max \\ Width\end{tabular}} &
  \textbf{LBs / BRAM} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Geometric Average \\ FPGA Area \\ (MWTAs)\\ W/O BRAM128K\\ Configured\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Geometric Average \\ FPGA Area \\ (MWTAs) \\ W/ BRAM128K \\ Configured\end{tabular}} \\ \hline
1 kbit   & 8   & 10 & \num{4.60349e8} & \num{4.92252e8} \\ \hline
2 kbit   & 16  & 10 & \num{3.37671e8} & \num{3.60046e8} \\ \hline
4 kbit   & 16  & 10 & \num{2.55735e8} & \num{2.72124e8} \\ \hline
8 kbit   & 32  & 10 & \num{2.16497e8} & \num{2.28926e8} \\ \hline
16 kbit  & 32  & 10 & \num{2.13938e8} & \num{2.25148e8} \\ \hline
32 kbit  & 64  & 25 & \num{2.20764e8} & \num{2.33258e8} \\ \hline
64 kbit  & 64  & 25 & \num{2.40827e8} & \num{2.52722e8} \\ \hline
128 kbit & 128 & 50 & \num{2.63587e8} & \num{2.76753e8} \\ \hline
\end{tabular}
\caption{Results with LUTRAM}
\label{tab:explore_results_lutram}
\end{table}

\clearpage
\subsubsection*{3.2.1 W.R.T Stratix-IV}

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{possible_error_1.jpg}
\caption{Checker output when BRAM128K is defined}
\label{fig:possible_error_1}
\end{figure}
\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{possible_error_2.jpg}
\caption{Checker output when BRAM128K is not defined}
\label{fig:possible_error_2}
\end{figure}

With respect to the original Stratix-IV architecture, some test results show that they can be more area efficient (BRAM sizes 8K, 16K and 32K with LUTRAM). This was an interesting observation since it suggested that simply having one type of BRAM was more efficient than what the industry actually implemented in a commercial product. To verify the results once more, the mapping tool was reprogrammed to program the Stratix-IV architecture to also only have a 8K BRAM only. 

The resulting mapping was the same. However, it was discovered that the checker executable provided computed different results depending if a third type of BRAM is defined or not. Fig. \ref{fig:possible_error_1} shows the output of the checker executable when BRAM128K is defined. The area computed for the first few circuits differ from that of those in Fig. \ref{fig:possible_error_2}. Fig. \ref{fig:possible_error_2} also shows a column for Type 3 and table entries are misaligned with the headers.

Due to the time of writing of this report being too close to the deadline, a conclusion cannot be drawn about the accuracy of the results. The rest of the evaluation/report will proceed with respect to the numbers collected in column 5 of Table \ref{tab:explore_results_no_lutram} and Table \ref{tab:explore_results_lutram}.

\clearpage
\subsubsection*{3.2.2 Trends}

First, the results show that area usage for the architecture with LUTRAMs are much lower than that without. This is likely due to the increased granularity in terms of available physical RAM sizes. LUTRAMs are much more efficient for logical RAMs that have a small size.

Next, for both results with and without LUTRAM, max width is seen increasing as max size increases. This is because the depth increases with the size of a BRAM assuming width stays the same. The depth demanded by logical RAMs are only so much and at some point in time, not having enough width means that many physical RAMs are required in parallel. The additional capacity that is provided by these physical RAMs (by the means of depth) is thus wasted. With RAM sharing being only possible for up to two logical RAMs at a time, this wastage translates to more physical RAMs being required and an increase in area usage.



\clearpage
\section*{4.0 Future Work}

Cost function to account for sharing better, perhaps hold off on solution until both are evaluated

Cost function also does not care about utilization of physical RAM directly as we are mapping logical RAMs in the order in which they are entered in the test case. As a result, physical RAMs might not be utilized in the best manner especially when it comes to having to instantiate ones that are not available given the current logic block size.

To improve the results further, we can explore algorithms that make use of "physical" RAMs that are made of the given, actually available physical RAMs. For example, in an architecture with LUTRAMs and BRAMs of different sizes, we can take some combination of each of them to construct a new "physical" RAM 

% ############################
% ############################

\clearpage
\section*{5.0 Appendix}
\subsection*{Appendix A: .py file for computing physical RAM usage}
\inputminted[breaklines]{Python}{check_pram_usage.py}

\clearpage
\subsection*{Appendix B: .py file for computing tile usage}
\inputminted[breaklines]{Python}{check_tile_usage.py}

\clearpage
\subsection*{Appendix C: .py file for computing circuit area usage}
\inputminted[breaklines]{Python}{check_circuit_area.py}

\clearpage
\subsection*{Appendix D: .py file for exploring single type of physical ram}
\inputminted[breaklines]{Python}{explore_single_bram.py}

\clearpage
\subsection*{Appendix E: Dump file for exploring single type of physical ram with BRAM128K configured}
\inputminted[breaklines]{text}{explore_details_full_2}

% ############################
% ############################

\end{document}

