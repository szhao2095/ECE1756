\documentclass[12pt,letterpaper]{article}
\usepackage{fullpage}
\usepackage[top=2cm, bottom=4.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{lastpage}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage[table,xcdraw]{xcolor}
\usepackage{siunitx}
\usepackage{minted}

\hypersetup{%
  colorlinks=true,
  linkcolor=blue,
  linkbordercolor={0 0 1}
}

\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}

% Edit these as appropriate
\newcommand\course{ECE 1756}
\newcommand\hwnumber{3}
\newcommand\NetIDa{1003273913}

\pagestyle{fancyplain}
\headheight 35pt
\lhead{\NetIDa}
\chead{\textbf{\Large Assignment \hwnumber}}
\rhead{\course \\ \today}
\lfoot{}
\cfoot{}
\rfoot{\small\thepage}
\headsep 1.5em

\begin{document}

\section*{1.0 Introduction}

The following document serves as the lab report for assignment 3 of ECE 1756 (Fall 2021). This report is written by Sheng Zhao (1003273913).

Section 2.0 describes the C++ implementation of the desired logical RAM mapping application as well as the the means by which it is further optimized. Section 3.0 then presents and evaluates the mappings produced by this implementation. Finally, a brief Section 4.0 covers the potential future work that can be done to improve upon the current implementation.

\clearpage
\section*{2.0 RAM Mapper}

The objective of the assignment is to create a RAM mapping tool that produces a legal mapping of desired logical RAMs to available physical RAMs. A total of roughly 15000 different logical RAMs across 69 circuits serves as the benchmark of the implementation, with the area metric calculated by the checker executable provided by the course serving as the evaluation criteria. Details of the problem statement can be found within the lab manual.

The RAM mapping functionality is implemented using C++ in an Object Oriented Programming fashion. This section details the process that led to the final implementation. Skip to subsection 2.4 for the final implementation. Big O notation will only be given for the final implementation's core calculations (initialization portions are skipped). Note that due to time constraints, the implementation only ever map logical RAMs to a single type of physical RAM.

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{single_ram_pram_usage.png}
\caption{Physical RAM usage for single ram type mapping}
\label{fig:single_ram_pram_usage}
\end{figure}
\clearpage

To help illustrate how well the instantiated physical RAMs are being utilized, Fig. \ref{fig:single_ram_pram_usage} (python code used to generate this can be found in Appendix A) was generated by first computing the percentage of total logical bits over the total physical bits within the RAM that it is mapped to. The 15000 total data points are then placed into ten buckets based on this percentage value. In essence, the intuition is that the larger the utilization the better (and less area is wasted) and this is represented with a higher count in the lower buckets (on the left). 

In general, it would seem like the final implementation (in red) has shown an improvement when compared to the initial implementation (in blue). There is a decrease in counts for buckets for 50\%~90\% and increase in counts for buckets of lower wastage percentages. However, the final bucket for 90\%~100\% showed an increase which suggest that some other optimization method other than sharing and improving the cost function (explained in the following subsections) might be required.

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{single_ram_tile_usage.png}
\caption{Tile usage for single ram type mapping}
\label{fig:single_ram_tile_usage}
\end{figure}

A similar computation is done for Fig. \ref{fig:single_ram_tile_usage} (python code in Appendix B) for how well the logic block count relates to the total final tile count. Having a large discrepancy between the two values for each circuit (graphically this means more data points falling in the lower buckets, i.e. lower usage) means that one physical RAM type might be overused, leading to more tiles being needed. As shown in the figure, the final implementation (in red) showed improvement over the initial (in blue) with more circuits utilizing more of the available tiles. 

\clearpage
\subsection*{2.1 Single Ram Type - Simple}

The RAM mapping tool began with just a simple idea, to map each logical RAM, regardless of which circuit they belong to. The main computation essentially produces a solution for each logical RAM requested for each type of physical RAM, and the lowest cost solution is then chosen to be the final solution. In the event that the physical RAM can operate in different widths, all combinations that do not violate any legality checks are considered. To keep computations simple, the cost function used is simply the area of the physical RAM used (i.e. logic block areas for LUTRAMs, BRAM areas for BRAMs, additional required LUTs are included). 

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{single_ram_circuit_area_checker_simple.png}
\caption{Area usage for simple implementation}
\label{fig:single_ram_circuit_area_checker_simple}
\end{figure}

\clearpage
\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{checker_simple_area.jpg}
\caption{Geometric average for simple implementation}
\label{fig:checker_simple_area}
\end{figure}

With the simple implementation, a mapping was computed and evaluated using the provided checker executable. A geometric average area of \num{2.63699e8} MWTAs (Fig. \ref{fig:checker_simple_area}) is obtained and Fig. \ref{fig:single_ram_circuit_area_checker_simple} (python script in Appendix C) shows the area usage for each of the 69 circuits.

In addition, with respect to Fig. \ref{fig:single_ram_pram_usage}, The simple implementation (shown in blue) seems to be under utilizing the physical RAMs that are instantiated as most of these physical RAMs are seeing more than 50\% of their available space wasted.

\clearpage
\subsection*{2.2 Single Ram Type - Shared}

With under utilization in mind, an effort was made to share the physical RAMs are much as possible. To facilitate the sharing of physical RAM, a map of logical RAM width to a vector of logical RAM IDs is created during initialization when the test cases are being read in. The vectors of logical RAMs are also sorted based on the logical RAM depth in descending order.

Building on top of the simple implementation, every time a solution is explored for the current logical RAM, a lookup is also performed into this newly created map. This is done first with the width that is currently being explored and, should no valid candidate be found, smaller widths in powers of two. Each candidate is checked for validity based on their required modes, the physical RAM's current operating mode, whether if their width is possible with the physical RAM in TrueDualPort mode, whether if they are already mapped, etc. The cost function for the current logical RAM is adjusted according to the ratio of the two logical RAM's total bit requirements. This translates to a strict decrease in cost in all cases. Should a solution with RAM sharing be chosen, this entry is recorded twice, once for each logical RAM, and both logical RAMs are marked as done.

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{single_ram_circuit_area_checker_shared.png}
\caption{Area usage for shared implementation}
\label{fig:single_ram_circuit_area_checker_shared}
\end{figure}

\clearpage
\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{checker_shared_area.jpg}
\caption{Geometric average for shared implementation}
\label{fig:checker_shared_area}
\end{figure}

With the shared implementation, a geometric average area of \num{2.64334e8} MWTAs (Fig. \ref{fig:checker_simple_area}) is obtained which is higher than before. The breakdown of area usage in Fig. \ref{fig:single_ram_circuit_area_checker_simple} shows that while circuit 59 has seen a halving in area requirement, many other circuits are in fact using more area than before. This is likely due to the inaccurate cost function which only accounts for the current logical RAM that is being evaluated.

It is also interesting to note that Fig. \ref{fig:single_ram_pram_usage} shows that sharing physical RAM does indeed increase utilization. However, the increase in geomtric average area suggests that the initial intuition of percentage of physical RAM utilized is closely related to area is untrue.

\clearpage
\subsection*{2.3 Single Ram Type - Modified Cost Function}

With the cost function in mind, an implementation was done on top of the simple implementation as a proof of concept with lower complexity in the code. The improved cost function does not only account for the area required by the physical RAMs themselves, but also any additional area incurred when the use of the desired physical RAM requires more logic blocks. For example, if based on the current number of logic blocks there are only X number of BRAM8192 blocks and the current solution (that is being evaluated) requires Y more than the limit, the cost function will also include the instantiation of an addition Y times the ratio (10 in this case for Stratix-IV) number of logic blocks. 

The modified cost function begins by computing the existing amount of each type of physical RAM based on the logic blocks used for the circuit logic. With each iteration, the number and type of physical RAM chosen for each solution is recorded. When a potential solution seeks to use a RAM type that is not available anymore, the addition cost is accounted for. This has the effect of delaying the use of unavailable physical RAM type. When a solution is chosen, and should it exceed the currently available amount, a new total of each RAM type is computed based on the new logic block count (e.g. using an extra BRAM128K causes 300 more logic blocks to be added, which is 30 more BRAM8192 blocks).

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{single_ram_circuit_area_checker_modifiedcostfunction.png}
\caption{Area usage for modified cost function implementation}
\label{fig:single_ram_circuit_area_checker_modifiedcostfunction}
\end{figure}

\clearpage
\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{checker_modifiedcostfunction_area.jpg}
\caption{Geometric average for modified cost function implementation}
\label{fig:checker_modifiedcostfunction_area}
\end{figure}

The modified cost function is a success and brought the geometric average area down to \num{2.22393e8} MWTAs (Fig. \ref{fig:checker_modifiedcostfunction_area}) and Fig. \ref{fig:single_ram_circuit_area_checker_modifiedcostfunction} also shows a significant decrease in area used for many circuits.

\clearpage
\subsection*{2.4 Single Ram Type - Modified Cost Function with Sharing}

Getting to the final implementation, the modified cost function and physical RAM sharing components are merged into a single function with both implementations still operating the same way they did before.

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{single_ram_circuit_area_checker_modifiedcostfunction_withsharing.png}
\caption{Area usage for modified cost function with physical RAM sharing implementation}
\label{fig:single_ram_circuit_area_checker_modifiedcostfunction_withsharing}
\end{figure}
\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{checker_modifiedcostfunction_withsharing_area.jpg}
\caption{Geometric average for modified cost function with physical RAM sharing implementation}
\label{fig:checker_modifiedcostfunction_withsharing_area}
\end{figure}

The addition of the physical RAM sharing portion further improved the geometric average area to \num{2.1939e8} MWTAs (Fig. \ref{fig:checker_modifiedcostfunction_withsharing_area}). Similar to when we switched from simple to shared implementations Fig. \ref{fig:single_ram_circuit_area_checker_modifiedcostfunction_withsharing} shows the same decrease for circuit 59 and a very slight increase in area usage for circuits 38.

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{run_time.jpg}
\caption{Average time taken}
\label{fig:run_time}
\end{figure}

The final implementation took an average of 0.35 seconds to complete the entire computation (including initialization) over 20 runs (Fig. \ref{fig:run_time}). The command needed to run the mapping tool with Stratix-IV architecture is ./mapper 1.

\clearpage
\subsubsection*{2.4.1 Big O}

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{big_o.jpg}
\caption{Pseudocode for main computation}
\label{fig:big_o}
\end{figure}

With the following variable definitions:
\begin{itemize}
  \item N - Total number of test cases
  \item T - Total number of physical RAM types
  \item W - Total valid width settings for a given physical RAM type
  \item C - Denoting constant time computation
\end{itemize}
The Big-O notation for the main computation is given by $O(N^2*T*W^2 + N*T*W\log{}W + N*T\log{}T + N*T)$.

\clearpage
\section*{3.0 Results}

\subsection*{3.1 Stratix-IV Architecture}

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{table_1_top.jpg}
\caption{Checker output for Stratix-IV architecture (top)}
\label{fig:table_1_top}
\end{figure}
\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{table_1_bot.jpg}
\caption{Checker output for Stratix-IV architecture (bot)}
\label{fig:table_1_bot}
\end{figure}

\clearpage
\subsection*{3.2 Single Physical RAM Type w/ and w/o LUTRAMs}

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{single_ram_explore_summary_1.jpg}
\caption{Explore summary}
\label{fig:single_ram_explore_summary_1}
\end{figure}

To facilitate the design exploration with a single type of physical RAM with and without LUTRAMs, a short python script (Appendix D) was written that works in conjunction with the mapping tool to execute the roughly 600 different combinations of max BRAM size, with different widths and ratios, as well as with and without LUTRAMs. For each max size from 1K to 128K, widths of 2 to 128 bits are tested. Each set of these different max widths are also tested with ratios of 10, 25, 50, 100 (for sizes up to 16K), 150 (for 32K), 200 (for 64K), 300 (for 128K). Finally, the whole test set is rerun with LUTRAMs enabled.

Fig. \ref{fig:single_ram_explore_summary_1} shows the summary of the exploration and the full dump file can be found in Appendix E. Results shown in Fig. \ref{fig:single_ram_explore_summary_1} is used to prepare Table \ref{tab:explore_results_no_lutram} and Table \ref{tab:explore_results_lutram}.

\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{\begin{tabular}[c]{@{}c@{}}BRAM\\ Size\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Max \\ Width\end{tabular}} &
  \textbf{LBs / BRAM} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Geometric Average \\ FPGA Area \\ (MWTAs)\\ W/O BRAM128K\\ Configured\end{tabular}} \\ \hline
1 kbit   & 32  & 10 & \num{5.9361e8} \\ \hline
2 kbit   & 32  & 10 & \num{3.93535e8} \\ \hline
4 kbit   & 32  & 10 & \num{2.93704e8} \\ \hline
8 kbit   & 32  & 10 & \num{2.45787e8} \\ \hline
16 kbit  & 64  & 10 & \num{2.3384e8} \\ \hline
32 kbit  & 64  & 10 & \num{2.53859e8} \\ \hline
64 kbit  & 128 & 25 & \num{3.00032e8} \\ \hline
128 kbit & 128 & 25 & \num{3.57256e8} \\ \hline
\end{tabular}
\caption{Results without LUTRAM}
\label{tab:explore_results_no_lutram}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{\begin{tabular}[c]{@{}c@{}}BRAM\\ Size\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Max \\ Width\end{tabular}} &
  \textbf{LBs / BRAM} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Geometric Average \\ FPGA Area \\ (MWTAs)\\ W/O BRAM128K\\ Configured\end{tabular}}\\ \hline
1 kbit   & 8   & 10 & \num{4.60345e8} \\ \hline
2 kbit   & 16  & 10 & \num{3.37596e8} \\ \hline
4 kbit   & 16  & 10 & \num{2.55638e8} \\ \hline
8 kbit   & 32  & 10 & \num{2.16381e8} \\ \hline
16 kbit  & 32  & 10 & \num{2.14437e8} \\ \hline
32 kbit  & 64  & 25 & \num{2.19984e8} \\ \hline
64 kbit  & 64  & 25 & \num{2.36324e8} \\ \hline
128 kbit & 128 & 50 & \num{2.57645e8} \\ \hline
\end{tabular}
\caption{Results with LUTRAM}
\label{tab:explore_results_lutram}
\end{table}

\clearpage
\subsubsection*{3.2.1 W.R.T Stratix-IV}

With respect to the original Stratix-IV architecture, some test results show that they can be more area efficient (BRAM sizes 8K, 16K and 32K with LUTRAM). This was an interesting observation since it suggested that simply having one type of BRAM was more efficient than what the industry actually implemented in a commercial product. The reason for a smaller area is likely due to the lack of BRAM128K, which means area that was previously dedicated to these BRAMs are now freed.

\subsubsection*{3.2.2 Trends}

First, the results show that area usage for the architecture with LUTRAMs are much lower than that without. This is likely due to the increased granularity in terms of available physical RAM sizes. LUTRAMs are much more efficient for logical RAMs that have a small size.

Next, for both results with and without LUTRAM, max width is seen increasing as max size increases. This is because the depth increases with the size of a BRAM assuming width stays the same. The depth demanded by logical RAMs are only so much and at some point in time, not having enough width means that many physical RAMs are required in parallel. The additional capacity that is provided by these physical RAMs (by the means of depth) is thus wasted. With RAM sharing being only possible for up to two logical RAMs at a time, this wastage translates to more physical RAMs being required and an increase in area usage.

As for logic blocks per BRAM, the larger sized BRAMs seem to prefer a higher ratio. Once again, just like the observation with respect to Stratix-IV, having these large BRAMs too common will bump up the area since too many of them are present and not all of them might be used (as supported by examining the output table of checker executable, where many circuits do not utilize all available BRAMs).

Finally for the geometric average area computed, the trend is that the lowest values are found for medium sized BRAMs. This is likely due to them having the best balance between total capacity and area. BRAMs that are too small require many more to be instantiated in series or parallel, with additional LUTs and/or wastage of capacity adding up, leading to inefficient use of area. BRAMs that are too large also experience the same issue.

\clearpage
\subsection*{3.3 Custom Architecture}

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{explore_summary_custom.jpg}
\caption{Explore summary for custom architecture}
\label{fig:explore_summary_custom}
\end{figure}

Once again, to facilitate the exploration of custom architectures, a python script (Appendix F, full dump file in Appendix G) is written to feed custom test cases into the mapping tool as well as automatically evaluate it using the checker executable and record the results. In terms of the explored architecture, one with LUTRAM enabled and two additional types of BRAM is chosen. LUTRAM size and widths are the same as Stratix-IV and only the ratio is varied. As for BRAMs, 8K, 32K, 64K and 128K sizes with varying widths and ratios are tested due to the better performance as seen from before.

Of all the architectures tested, the best result came from one with 10\% LUTRAMs, BRAM8192 (max width 32, ratio 10), BRAM128K (max width 64, ratio 150) with a geometric average area of \num{2.09068e8}. 

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{area_difference.png}
\caption{Comparison between Stratix-IV and custom architecture}
\label{fig:area_difference}
\end{figure}

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{circuit_49_diff.jpg}
\caption{Comparison between circuit 49s}
\label{fig:circuit_49_diff}
\end{figure}

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{circuit_0_diff.jpg}
\caption{Comparison between circuit 0s}
\label{fig:circuit_0_diff}
\end{figure}

Area usage across the 69 circuits for both the Stratix-IV and custom architectures are plotted in Fig. \ref{fig:area_difference} (python script in Appendix H). The figure shows that most circuits gained an area reduction while a select few ended up with larger areas than before. A large portion of area reduction is likely related to the lower ratio of BRAM128K. Taking circuits 32, 49 (Fig. \ref{fig:circuit_49_diff}) and 67 for instance, these circuits show the largest area reduction and closer inspection into the results generated by the checker executable shows that the number of BRAM128K used is much more than for Stratix-IV. On the other hand, other circuits like circuit 0 (Fig. \ref{fig:circuit_0_diff}) suffered an area increase due to the lower LUTRAM count.

\clearpage
\section*{4.0 Future Work}

Cost function can be improved to account for sharing better. The current implementation only considers the computation for the current logical RAM being evaluated. The other chosen logical RAM gets mapped to the same physical RAM if the cost of the sharing solution is the lowest for the current logical RAM regardless if there might be a better solution for the other one. A better solution would perhaps hold off on deciding a solution until both are evaluated. However, this leads to a much more complex algorithm which the current implementation is unsuited for. Such an algorithm would not choose any solution until all potential ones are computed instead of doing so one by one like the current implementation.

Cost function also does not care about utilization of physical RAM directly during the mapping of logical RAMs, which are evaluated in the order in which they are entered in the test case file. As a result, physical RAMs might not be utilized in the best manner especially when it comes to having to instantiate ones that are not available given the current logic block size. A smaller sized logical RAM might get mapped to a BRAM128K, since that might be the only one that is available without instantiated more logical blocks, which is inefficient if the next logical RAM can utilize the BRAM128K better. The current smaller sized one can then map to a newly available LUTRAM or BRAM8192 since 300 more logical blocks will be added. 

To improve the results further, we can explore algorithms that make use of "physical" RAMs that are made of the given, actually available physical RAMs. For example, in an architecture with LUTRAMs and BRAMs of different sizes, we can take some combination of each of them to construct a new "physical" RAM which can then be added to the list of physical RAMs to be evaluated. Since there are infinitely many combinations, some amount of heuristics will have to be used to determine what some of the efficient ways logical RAMs can be grouped together. This insight and specialized mapping technique will then only be used for particular combinations logical RAMs with the right depths and widths.

% ############################
% ############################

\clearpage
\section*{5.0 Appendix}
\subsection*{Appendix A: .py file for computing physical RAM usage}
\inputminted[breaklines]{Python}{check_pram_usage.py}

\clearpage
\subsection*{Appendix B: .py file for computing tile usage}
\inputminted[breaklines]{Python}{check_tile_usage.py}

\clearpage
\subsection*{Appendix C: .py file for computing circuit area usage}
\inputminted[breaklines]{Python}{check_circuit_area.py}

\clearpage
\subsection*{Appendix D: .py file for exploring single type of physical ram}
\inputminted[breaklines]{Python}{explore_single_bram.py}

\clearpage
\subsection*{Appendix E: Dump file for exploring single type of physical ram}
\inputminted[breaklines]{text}{explore_details_full_1}

\clearpage
\subsection*{Appendix F: .py file for exploring custom architecture}
\inputminted[breaklines]{text}{explore_custom_arch.py}

\clearpage
\subsection*{Appendix G: Dump file for exploring custom architecture}
\inputminted[breaklines]{text}{explore_details_custom}

\clearpage
\subsection*{Appendix H: .py file for comparing architectures}
\inputminted[breaklines]{text}{compare_area.py}

% ############################
% ############################

\end{document}




for circuit in all_circuits
    for logical_ram in all_logical_rams
        ## First two for loops combine to be ~15000 O(N)
        
        for physical_ram in all_physical_rams
            ## Up to 3 types O(T)
            
            for width_setting in all_possible_widths
                ## Up to 8 for 128bit width
                ## If combined with BRAM type loop O(W)
                
                // Compute P depending on logical width
                // Compute S depending on logical depth
                // Compute additional LUTs depending on S
                // Compute area based on P, S, additional LUTs
                // Compute cost based on area, physical_ram availability by type
                ## Constant time computations above O(C)
                
                
                // Search for compatible sharing target
                for width in widths less than or equal to width_setting
                    ## Up to 7 for 64bit width, since TrueDualPort cannot run at 128bit width  O(W)
                
                    for logical_ram in logical_ram_ROM_SinglePORT
                        ## Cannot be more than 15000 (N)
                        
                        // Check for legality
                        // If found, insert potential match, goto EndOfLoop;
                        ## Constant time computations above O(C)
						=== O(N*T*W*W*N)
                        
                // Insert potential solution
            // Get lowest cost solution across all width_setting
            ## Sort used, O(W log W), W is size of solution array, same as potential widths
            ## W up to 8 for 128 bit width O(W)
			=== O(N*T*W*logW)
            
        // Get lowest cost solution across all_physical_rams
        ## Sort used, O(T log T), T is size of solution array, same as BRAM types
        ## T up to 3 O(T)
		=== O(N*T*logT)
            
        // Choose lowest cost solution
        // If sharing, update other logical_ram to be solved
        ## Constant time computations above O(C)
        
        for physical_ram in all_physical_rams
            ## Up to 3 types O(T)
			=== O(N*T)
            
            // Update available physical_ram counts by type
            ## Constant time computations above O(C)
            
			
NTW WN + NT WlogW + N TlogT	+ N T	

NT(WWN + WlogW + logT + 1)	
			
			
			
			
			
			
			
			